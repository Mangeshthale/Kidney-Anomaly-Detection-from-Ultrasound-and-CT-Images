{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"adityasinghsengar122/analytica-main-problem\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2XY7SM3Cyml",
        "outputId": "d87a4df1-90ec-4910-fb90-1db359e39798"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'analytica-main-problem' dataset.\n",
            "Path to dataset files: /kaggle/input/analytica-main-problem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "base_dir = \"/kaggle/input/analytica-main-problem\"\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    print(root)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBUR0MHnC_N-",
        "outputId": "ff6a16a4-b453-471e-8dc1-1289dcdda427"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/analytica-main-problem\n",
            "/kaggle/input/analytica-main-problem/test\n",
            "/kaggle/input/analytica-main-problem/test/tumors\n",
            "/kaggle/input/analytica-main-problem/test/cysts\n",
            "/kaggle/input/analytica-main-problem/test/normal\n",
            "/kaggle/input/analytica-main-problem/test/stones\n",
            "/kaggle/input/analytica-main-problem/train\n",
            "/kaggle/input/analytica-main-problem/train/tumors\n",
            "/kaggle/input/analytica-main-problem/train/cysts\n",
            "/kaggle/input/analytica-main-problem/train/normal\n",
            "/kaggle/input/analytica-main-problem/train/stones\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Define input/output paths\n",
        "input_train = \"/kaggle/input/analytica-main-problem/train\"\n",
        "input_test  = \"/kaggle/input/analytica-main-problem/test\"\n",
        "\n",
        "output_train = \"/kaggle/working/processed_data/train\"\n",
        "output_test  = \"/kaggle/working/processed_data/test\"\n"
      ],
      "metadata": {
        "id": "_6eC2BM3DZeT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================\n",
        "# ğŸ”¹ Step 1: Preprocessing functions\n",
        "# ============================\n",
        "\n",
        "def preprocess_ultrasound(img):\n",
        "    \"\"\"Preprocessing pipeline for ultrasound kidney images.\"\"\"\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Remove speckle noise\n",
        "    denoised = cv2.medianBlur(gray, 3)\n",
        "    denoised = cv2.bilateralFilter(denoised, 5, 75, 75)\n",
        "\n",
        "    # Enhance contrast (CLAHE)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    enhanced = clahe.apply(denoised)\n",
        "\n",
        "    # Normalize intensity (0â€“1)\n",
        "    normalized = cv2.normalize(enhanced, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "    return normalized\n",
        "\n",
        "\n",
        "def preprocess_ct(img):\n",
        "    \"\"\"Preprocessing pipeline for CT kidney images.\"\"\"\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Light Gaussian smoothing\n",
        "    blurred = cv2.GaussianBlur(gray, (3,3), 0)\n",
        "\n",
        "    # Equalize histogram for consistent contrast\n",
        "    equalized = cv2.equalizeHist(blurred)\n",
        "\n",
        "    # Normalize intensity (0â€“1)\n",
        "    normalized = cv2.normalize(equalized, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "    return normalized\n",
        "\n",
        "\n",
        "# ============================\n",
        "# ğŸ”¹ Step 2: Simple modality detector (CT vs Ultrasound)\n",
        "# ============================\n",
        "\n",
        "def detect_modality(img):\n",
        "    \"\"\"\n",
        "    Rough heuristic:\n",
        "    Ultrasound images â†’ darker backgrounds, higher noise variance\n",
        "    CT images â†’ brighter, smoother texture\n",
        "    \"\"\"\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    var = np.var(gray)\n",
        "    mean_intensity = np.mean(gray)\n",
        "\n",
        "    if var > 500 and mean_intensity < 100:\n",
        "        return 'ultrasound'\n",
        "    else:\n",
        "        return 'ct'\n",
        "\n",
        "\n",
        "# ============================\n",
        "# ğŸ”¹ Step 3: Full dataset preprocessing function\n",
        "# ============================\n",
        "\n",
        "def preprocess_dataset(input_dir, output_dir):\n",
        "    \"\"\"\n",
        "    Applies modality-specific preprocessing to all images in a dataset.\n",
        "    Folder structure (example):\n",
        "        input_dir/\n",
        "            cyst/\n",
        "            normal/\n",
        "            stone/\n",
        "            tumor/\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    categories = ['cysts', 'normal', 'stones', 'tumors']\n",
        "\n",
        "    for category in categories:\n",
        "        src_path = os.path.join(input_dir, category)\n",
        "        dst_path = os.path.join(output_dir, category)\n",
        "        os.makedirs(dst_path, exist_ok=True)\n",
        "\n",
        "        print(f\"\\nğŸ”§ Processing category: {category}\")\n",
        "\n",
        "        for file in tqdm(os.listdir(src_path)):\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif')):\n",
        "                img_path = os.path.join(src_path, file)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is None:\n",
        "                    continue\n",
        "\n",
        "                # Decide modality and preprocess\n",
        "                modality = detect_modality(img)\n",
        "                if modality == 'ultrasound':\n",
        "                    processed = preprocess_ultrasound(img)\n",
        "                else:\n",
        "                    processed = preprocess_ct(img)\n",
        "\n",
        "                # Convert back to 8-bit for saving\n",
        "                processed_uint8 = (processed * 255).astype(np.uint8)\n",
        "\n",
        "                save_path = os.path.join(dst_path, file)\n",
        "                cv2.imwrite(save_path, processed_uint8)\n",
        "\n",
        "    print(\"\\nâœ… Preprocessing completed successfully!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NDXmd_AUDo9x"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preprocess_dataset(input_train, output_train)\n",
        "preprocess_dataset(input_test, output_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8Jt7-kkD1nm",
        "outputId": "cd32ec53-c6d4-4781-bf85-c7b1235da6fe"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”§ Processing category: cysts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2528/2528 [01:01<00:00, 41.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”§ Processing category: normal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4499/4499 [01:37<00:00, 46.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”§ Processing category: stones\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3708/3708 [01:22<00:00, 45.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”§ Processing category: tumors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2353/2353 [00:56<00:00, 41.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Preprocessing completed successfully!\n",
            "\n",
            "ğŸ”§ Processing category: cysts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 496/496 [00:02<00:00, 191.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”§ Processing category: normal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 861/861 [00:04<00:00, 199.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”§ Processing category: stones\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 715/715 [00:03<00:00, 195.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”§ Processing category: tumors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 444/444 [00:02<00:00, 185.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Preprocessing completed successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "REsUEIQoEWzu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}